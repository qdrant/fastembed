{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef06fb5d0f1a68c8",
   "metadata": {},
   "source": "MUVERA (**Mu**lti-**Ve**ctor **R**etrieval **A**lgorithm) is an algorithm that transforms variable-length sequences of vectors into Fixed Dimensional Encodings (FDEs) described in the [paper](https://arxiv.org/abs/2405.19504). This is particularly useful for converting multi-vector representations from late interaction models (like ColBERT) into fixed-size embeddings that can be efficiently stored and searched."
  },
  {
   "cell_type": "markdown",
   "id": "f2f81913084b1a22",
   "metadata": {},
   "source": [
    "## ü§ù MUVERA with FastEmbed\n",
    "\n",
    "The original paper suggests using the created FDEs for initial retrieval and original multi-vector representations for reranking to achieve the best quality of the results. FastEmbed implements the MUVERA algorithm as a postprocessor, not a separate model, so you can pass the sequence of vectors from the late interaction model to the postprocessor and get the FDE as a result. By implementing it that way, we ensure you don't need to encode your data with a multi-vector model twice if you decide to keep both representations.\n",
    "\n",
    "If you used multi-vector model before, then you have probably created an instance of it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23709588e9bfc403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:08:53.742140Z",
     "start_time": "2025-07-11T15:08:49.351855Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:03<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from fastembed.late_interaction.colbert import Colbert\n",
    "\n",
    "model = Colbert(model_name=\"answerdotai/answerai-colbert-small-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c7538a026c991",
   "metadata": {},
   "source": "Adding MUVERA embeddings requires postprocessing the embeddings generated by your multi-vector encoder. Let's import the FastEmbed's MUVERA implementation and set it up specifically for the model we use. MUVERA needs to know the dimensionality of the individual vectors that your model creates, so we can eiter set it up manually or just pass a model instance to a helper class method `.from_multivector_model`:"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "478914a84c8516a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:08:53.830455Z",
     "start_time": "2025-07-11T15:08:53.823539Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastembed.postprocess.muvera import MuveraPostprocessor\n",
    "\n",
    "muvera_postprocessor = MuveraPostprocessor.from_multivector_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56bfb49efb9db7",
   "metadata": {},
   "source": [
    "## üóÇÔ∏è Ingesting the documents\n",
    "\n",
    "The original paper separates processing the document embeddings (the ones we store in the Qdrant collection to search over), from the query embeddings and calculate them in a slightly different way. Thus, there are different processing methods, depending on whether you encode document or queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0518c6ef696a41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:08:53.959852Z",
     "start_time": "2025-07-11T15:08:53.872938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240,)\n"
     ]
    }
   ],
   "source": [
    "multivectors = model.passage_embed(\n",
    "    [\n",
    "        \"Paris is a capital of France\",\n",
    "        \"Berlin is a capital of Germany\",\n",
    "        \"The best chestnuts are in Place Pigalle\",\n",
    "    ]\n",
    ")\n",
    "fde_vectors = [muvera_postprocessor.process_document(v) for v in multivectors]\n",
    "print(fde_vectors[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411028b2bdb33ac1",
   "metadata": {},
   "source": [
    "## üîé Querying\n",
    "\n",
    "When querying, we use a different method of the `MuveraPostprocessor` to convert the multi-vector representations into FDEs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae95c8ee5bb59a29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:08:53.981466Z",
     "start_time": "2025-07-11T15:08:53.965051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240,)\n"
     ]
    }
   ],
   "source": [
    "query_multivector = next(model.query_embed(\"French cuisine\"))\n",
    "query_fde = muvera_postprocessor.process_query(query_multivector)\n",
    "print(query_fde.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199c5365fbebcfc4",
   "metadata": {},
   "source": [
    "## ü¶Ä Usage with Qdrant\n",
    "\n",
    "If you want to reproduce the whole process as described in the MUVERA paper, you have to create a single Qdrant collection with two [named vectors](https://qdrant.tech/documentation/concepts/vectors/#named-vectors): one for the multi-vector representation and one for the MUVERA embedding. The latter one has a dimensionality that depends on how you configure the parameters of the MUVERA projection and might be checked by inspecting the `.embedding_size` property of the postprocessor. This will be useful for properly configuring the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6e363c3db0cd7bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T15:08:54.025254Z",
     "start_time": "2025-07-11T15:08:54.021436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10240"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muvera_postprocessor.embedding_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
