{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:13:23.806907Z",
     "start_time": "2024-05-31T18:13:23.797078Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:14:31.147674Z",
     "start_time": "2024-05-31T18:14:31.134015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastembed import (\n",
    "    SparseTextEmbedding,\n",
    "    TextEmbedding,\n",
    "    LateInteractionTextEmbedding,\n",
    "    ImageEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Text Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:13:25.863008Z",
     "start_time": "2024-05-31T18:13:25.837795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dim</th>\n      <th>description</th>\n      <th>size_in_GB</th>\n      <th>model_file</th>\n      <th>additional_files</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BAAI/bge-small-en-v1.5</td>\n      <td>384</td>\n      <td>Fast and Default English model</td>\n      <td>0.067</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BAAI/bge-small-zh-v1.5</td>\n      <td>512</td>\n      <td>Fast and recommended Chinese model</td>\n      <td>0.090</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n      <td>384</td>\n      <td>Sentence Transformer model, MiniLM-L6-v2</td>\n      <td>0.090</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>snowflake/snowflake-arctic-embed-xs</td>\n      <td>384</td>\n      <td>Based on all-MiniLM-L6-v2 model with only 22m ...</td>\n      <td>0.090</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>jinaai/jina-embeddings-v2-small-en</td>\n      <td>512</td>\n      <td>English embedding model supporting 8192 sequen...</td>\n      <td>0.120</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>snowflake/snowflake-arctic-embed-s</td>\n      <td>384</td>\n      <td>Based on infloat/e5-small-unsupervised, does n...</td>\n      <td>0.130</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BAAI/bge-small-en</td>\n      <td>384</td>\n      <td>Fast English model</td>\n      <td>0.130</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>nomic-ai/nomic-embed-text-v1.5-Q</td>\n      <td>768</td>\n      <td>Quantized 8192 context length english model</td>\n      <td>0.130</td>\n      <td>onnx/model_quantized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>BAAI/bge-base-en-v1.5</td>\n      <td>768</td>\n      <td>Base English model, v1.5</td>\n      <td>0.210</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sentence-transformers/paraphrase-multilingual-...</td>\n      <td>384</td>\n      <td>Sentence Transformer model, paraphrase-multili...</td>\n      <td>0.220</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Qdrant/clip-ViT-B-32-text</td>\n      <td>512</td>\n      <td>CLIP text encoder</td>\n      <td>0.250</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BAAI/bge-base-en</td>\n      <td>768</td>\n      <td>Base English model</td>\n      <td>0.420</td>\n      <td>model_optimized.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>snowflake/snowflake-arctic-embed-m</td>\n      <td>768</td>\n      <td>Based on intfloat/e5-base-unsupervised model, ...</td>\n      <td>0.430</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>nomic-ai/nomic-embed-text-v1</td>\n      <td>768</td>\n      <td>8192 context length english model</td>\n      <td>0.520</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>jinaai/jina-embeddings-v2-base-en</td>\n      <td>768</td>\n      <td>English embedding model supporting 8192 sequen...</td>\n      <td>0.520</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>nomic-ai/nomic-embed-text-v1.5</td>\n      <td>768</td>\n      <td>8192 context length english model</td>\n      <td>0.520</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>snowflake/snowflake-arctic-embed-m-long</td>\n      <td>768</td>\n      <td>Based on nomic-ai/nomic-embed-text-v1-unsuperv...</td>\n      <td>0.540</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n      <td>1024</td>\n      <td>MixedBread Base sentence embedding model, does...</td>\n      <td>0.640</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>sentence-transformers/paraphrase-multilingual-...</td>\n      <td>768</td>\n      <td>Sentence-transformers model for tasks like clu...</td>\n      <td>1.000</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>snowflake/snowflake-arctic-embed-l</td>\n      <td>1024</td>\n      <td>Based on intfloat/e5-large-unsupervised, large...</td>\n      <td>1.020</td>\n      <td>onnx/model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>BAAI/bge-large-en-v1.5</td>\n      <td>1024</td>\n      <td>Large English model, v1.5</td>\n      <td>1.200</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>thenlper/gte-large</td>\n      <td>1024</td>\n      <td>Large general text embeddings model</td>\n      <td>1.200</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>intfloat/multilingual-e5-large</td>\n      <td>1024</td>\n      <td>Multilingual model, e5-large. Recommend using ...</td>\n      <td>2.240</td>\n      <td>model.onnx</td>\n      <td>[model.onnx_data]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                model   dim  \\\n0                              BAAI/bge-small-en-v1.5   384   \n1                              BAAI/bge-small-zh-v1.5   512   \n2              sentence-transformers/all-MiniLM-L6-v2   384   \n3                 snowflake/snowflake-arctic-embed-xs   384   \n4                  jinaai/jina-embeddings-v2-small-en   512   \n5                  snowflake/snowflake-arctic-embed-s   384   \n6                                   BAAI/bge-small-en   384   \n7                    nomic-ai/nomic-embed-text-v1.5-Q   768   \n8                               BAAI/bge-base-en-v1.5   768   \n9   sentence-transformers/paraphrase-multilingual-...   384   \n10                          Qdrant/clip-ViT-B-32-text   512   \n11                                   BAAI/bge-base-en   768   \n12                 snowflake/snowflake-arctic-embed-m   768   \n13                       nomic-ai/nomic-embed-text-v1   768   \n14                  jinaai/jina-embeddings-v2-base-en   768   \n15                     nomic-ai/nomic-embed-text-v1.5   768   \n16            snowflake/snowflake-arctic-embed-m-long   768   \n17                 mixedbread-ai/mxbai-embed-large-v1  1024   \n18  sentence-transformers/paraphrase-multilingual-...   768   \n19                 snowflake/snowflake-arctic-embed-l  1024   \n20                             BAAI/bge-large-en-v1.5  1024   \n21                                 thenlper/gte-large  1024   \n22                     intfloat/multilingual-e5-large  1024   \n\n                                          description  size_in_GB  \\\n0                      Fast and Default English model       0.067   \n1                  Fast and recommended Chinese model       0.090   \n2            Sentence Transformer model, MiniLM-L6-v2       0.090   \n3   Based on all-MiniLM-L6-v2 model with only 22m ...       0.090   \n4   English embedding model supporting 8192 sequen...       0.120   \n5   Based on infloat/e5-small-unsupervised, does n...       0.130   \n6                                  Fast English model       0.130   \n7         Quantized 8192 context length english model       0.130   \n8                            Base English model, v1.5       0.210   \n9   Sentence Transformer model, paraphrase-multili...       0.220   \n10                                  CLIP text encoder       0.250   \n11                                 Base English model       0.420   \n12  Based on intfloat/e5-base-unsupervised model, ...       0.430   \n13                  8192 context length english model       0.520   \n14  English embedding model supporting 8192 sequen...       0.520   \n15                  8192 context length english model       0.520   \n16  Based on nomic-ai/nomic-embed-text-v1-unsuperv...       0.540   \n17  MixedBread Base sentence embedding model, does...       0.640   \n18  Sentence-transformers model for tasks like clu...       1.000   \n19  Based on intfloat/e5-large-unsupervised, large...       1.020   \n20                          Large English model, v1.5       1.200   \n21                Large general text embeddings model       1.200   \n22  Multilingual model, e5-large. Recommend using ...       2.240   \n\n                   model_file   additional_files  \n0        model_optimized.onnx                NaN  \n1        model_optimized.onnx                NaN  \n2                  model.onnx                NaN  \n3             onnx/model.onnx                NaN  \n4             onnx/model.onnx                NaN  \n5             onnx/model.onnx                NaN  \n6        model_optimized.onnx                NaN  \n7   onnx/model_quantized.onnx                NaN  \n8        model_optimized.onnx                NaN  \n9        model_optimized.onnx                NaN  \n10                 model.onnx                NaN  \n11       model_optimized.onnx                NaN  \n12            onnx/model.onnx                NaN  \n13            onnx/model.onnx                NaN  \n14            onnx/model.onnx                NaN  \n15            onnx/model.onnx                NaN  \n16            onnx/model.onnx                NaN  \n17            onnx/model.onnx                NaN  \n18            onnx/model.onnx                NaN  \n19            onnx/model.onnx                NaN  \n20                 model.onnx                NaN  \n21                 model.onnx                NaN  \n22                 model.onnx  [model.onnx_data]  "
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_models = (\n",
    "    pd.DataFrame(TextEmbedding.list_supported_models())\n",
    "    .sort_values(\"size_in_GB\")\n",
    "    .drop(columns=\"sources\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "supported_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Sparse Text Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:13:27.124747Z",
     "start_time": "2024-05-31T18:13:27.096212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>vocab_size</th>\n      <th>description</th>\n      <th>size_in_GB</th>\n      <th>sources</th>\n      <th>model_file</th>\n      <th>additional_files</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>prithvida/Splade_PP_en_v1</td>\n      <td>30522</td>\n      <td>Misspelled version of the model. Retained for ...</td>\n      <td>0.532</td>\n      <td>{'hf': 'Qdrant/SPLADE_PP_en_v1'}</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>prithivida/Splade_PP_en_v1</td>\n      <td>30522</td>\n      <td>Independent Implementation of SPLADE++ Model f...</td>\n      <td>0.532</td>\n      <td>{'hf': 'Qdrant/SPLADE_PP_en_v1'}</td>\n      <td>model.onnx</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Qdrant/bm42-all-minilm-l6-v2-attentions</td>\n      <td>30522</td>\n      <td>Light sparse embedding model, which assigns an...</td>\n      <td>0.090</td>\n      <td>{'hf': 'Qdrant/all_miniLM_L6_v2_with_attentions'}</td>\n      <td>model.onnx</td>\n      <td>[stopwords.txt]</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                     model  vocab_size  \\\n0                prithvida/Splade_PP_en_v1       30522   \n1               prithivida/Splade_PP_en_v1       30522   \n2  Qdrant/bm42-all-minilm-l6-v2-attentions       30522   \n\n                                         description  size_in_GB  \\\n0  Misspelled version of the model. Retained for ...       0.532   \n1  Independent Implementation of SPLADE++ Model f...       0.532   \n2  Light sparse embedding model, which assigns an...       0.090   \n\n                                             sources  model_file  \\\n0                   {'hf': 'Qdrant/SPLADE_PP_en_v1'}  model.onnx   \n1                   {'hf': 'Qdrant/SPLADE_PP_en_v1'}  model.onnx   \n2  {'hf': 'Qdrant/all_miniLM_L6_v2_with_attentions'}  model.onnx   \n\n  additional_files  \n0              NaN  \n1              NaN  \n2  [stopwords.txt]  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(SparseTextEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Supported Late Interaction Text Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:14:34.370252Z",
     "start_time": "2024-05-31T18:14:34.354270Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dim</th>\n      <th>description</th>\n      <th>size_in_GB</th>\n      <th>sources</th>\n      <th>model_file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>colbert-ir/colbertv2.0</td>\n      <td>128</td>\n      <td>Late interaction model</td>\n      <td>0.44</td>\n      <td>{'hf': 'colbert-ir/colbertv2.0'}</td>\n      <td>model.onnx</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                    model  dim             description  size_in_GB  \\\n0  colbert-ir/colbertv2.0  128  Late interaction model        0.44   \n\n                            sources  model_file  \n0  {'hf': 'colbert-ir/colbertv2.0'}  model.onnx  "
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(LateInteractionTextEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Supported Image Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T18:14:42.501881Z",
     "start_time": "2024-05-31T18:14:42.484726Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>dim</th>\n      <th>description</th>\n      <th>size_in_GB</th>\n      <th>sources</th>\n      <th>model_file</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Qdrant/clip-ViT-B-32-vision</td>\n      <td>512</td>\n      <td>CLIP vision encoder based on ViT-B/32</td>\n      <td>0.34</td>\n      <td>{'hf': 'Qdrant/clip-ViT-B-32-vision'}</td>\n      <td>model.onnx</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Qdrant/resnet50-onnx</td>\n      <td>2048</td>\n      <td>ResNet-50 from `Deep Residual Learning for Ima...</td>\n      <td>0.10</td>\n      <td>{'hf': 'Qdrant/resnet50-onnx'}</td>\n      <td>model.onnx</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                         model   dim  \\\n0  Qdrant/clip-ViT-B-32-vision   512   \n1         Qdrant/resnet50-onnx  2048   \n\n                                         description  size_in_GB  \\\n0              CLIP vision encoder based on ViT-B/32        0.34   \n1  ResNet-50 from `Deep Residual Learning for Ima...        0.10   \n\n                                 sources  model_file  \n0  {'hf': 'Qdrant/clip-ViT-B-32-vision'}  model.onnx  \n1         {'hf': 'Qdrant/resnet50-onnx'}  model.onnx  "
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(ImageEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.18 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4a27af61e455bc18dcf16f5867a2ff0402fa12b01dd0f6ce3a79ae73ad15e91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
